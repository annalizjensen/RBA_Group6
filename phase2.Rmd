---
title: "Phase2"
author: "Anna Liz Jensen,Keyur Joshi,Maridol Guillen, Brooke Haley"
date: "3/9/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(stringr)
library(dplyr)
library(tidyr)
library(VIM)
library(psych)
```

### Set Up

```{r}
user_reviews_filename = "googleplaystore_user_reviews.csv"
play_store_ratings = "googleplaystore.csv"
user_reviews_df = read.csv(user_reviews_filename)
user_ratings_df = read.csv(play_store_ratings, fill=T)
```

### Step 4 Clean & Tidy

```{r}
str(user_reviews_df)

```

```{r}
str(user_ratings_df)
```

#### Ugly Shifting

```{r}
# if you look at the data, row 10473 is a problem, it's shifted over. 
values_of_bad_row = user_ratings_df[10473,]
bad_row = user_ratings_df$Category == "1.9"

# suppress the warning here -- it's just complaining about converting a 
# str to char, but it actually works just fine in this case. 
suppressWarnings(user_ratings_df[bad_row, 3:(ncol(user_ratings_df))] <-
                   user_ratings_df[bad_row, 2:(ncol(user_ratings_df) -1)])

# I got these from the GPlay website. This is the only egregiously bad row, 
# and I have that available data, so this is more accurate than imputation
# for this one off value.
user_ratings_df[bad_row, 2] = "LIFESTYLE"
user_ratings_df[bad_row, 10] = "Lifestyle"

str(user_ratings_df) # annoyingly, things get converted to char after the shift. 
```

#### Coercion: Basic Transformations

```{r}

user_ratings_df$Reviews = as.numeric(user_ratings_df$Reviews)
user_ratings_df$Rating = as.numeric(user_ratings_df$Rating)

# \\D+ regex gsub keeps only digit chars
user_ratings_df$Installs = as.numeric(gsub("\\D+", "", user_ratings_df$Installs))
names(user_ratings_df)[6] = "Install Floor" # These are incremental, assume floors

# 
user_ratings_df$Type = as.logical(user_ratings_df$Type == "Free")
names(user_ratings_df)[7] = "Is Free"

user_ratings_df$Price = as.numeric(gsub("\\$", "", user_ratings_df$Price))

user_ratings_df$Size <- ifelse(user_ratings_df$Size == 'Varies with devices', np.nan, user_ratings_df$Size)
user_ratings_df$Size <- gsub('M', 'e6',user_ratings_df$Size)
user_ratings_df$Size <- gsub('k', 'e3', user_ratings_df$Size)
user_ratings_df$Size <- as.numeric(user_ratings_df$Size)

user_ratings_df$Last.Updated = as.Date(user_ratings_df$Last.Updated, 
                                         format = "%B %d, %Y")

user_ratings_df <- user_ratings_df %>%
  separate(
    Genres,
    c("Genre1", "Genre2"),
    sep = ";",
    fill = "right"
  )

str(user_ratings_df)
```

#### Coercion: Characters -> Numeric Bytes

```{r}

# I would like to convert Size to numeric bytes
# I will make a new column to do so where possible, because 'Varies with device'
# is not the same as NA and is still an interesting data point. 
# I'm adapting the solution specified here: https://stackoverflow.com/questions/10910688/converting-kilobytes-megabytes-etc-to-bytes-in-r

size_numeric = user_ratings_df$Size
unique(str_extract(size_numeric, ".$")) # only M and k matter, which is great
size_numeric = na_if(size_numeric, "Varies with device")

convert_to_num_bytes = function(x) {
   byte_sizes = c("k" = 1024, "M" = 1024^2)
   regex = "(\\d+\\.*\\d*)(k|M)"
   digits = as.numeric(sub(regex, "\\1", x))
   units = sub(regex, "\\2", x)
   digits * unname(byte_sizes[units])
}

size_numeric = convert_to_num_bytes(size_numeric)
user_ratings_df$Size_Numeric = size_numeric
str(user_ratings_df)
```

#### Coercion: Combining Data Sets

```{r}

## Using median as it's less sensitve to outliers [ We don't want one person putting like -1 affecting others ]
grouped_review_stats = user_reviews_df %>%
  select(App, Sentiment_Polarity, Sentiment_Subjectivity) %>%
  filter(!is.na(Sentiment_Polarity) & !is.na(Sentiment_Subjectivity)) %>%
  group_by(App) %>%
  summarize(
    n = n(), 
    median_polarity = median(Sentiment_Polarity),
    median_subjectivity = median(Sentiment_Subjectivity) 
  )

str(grouped_review_stats)

# It was at this point I discovered the review sentiment analysis only
# covers # and A-H named apps. 

# This is an example of Missing At Random. The missingness is not related to
# the actually missing variable, but mostly to the name of the app, which is
# related. Keyur, maybe we can do a test to verify that assertion?

#Testing for MAR between Sentiment_Polarity and AppName




combined = merge(x = user_ratings_df, 
                 y = grouped_review_stats,
                 by = "App",
                 all.x = T)

str(combined)
```

#### Imputation

```{r}
# so... honestly, i'm missing too many sentiment analysis vars for 
# imputation to be of any use here. BUT we can try imputing ratings here!
# what would be a good way to impute?
# But we can confirm if it's MAR wrt to starting alphabet

combined_missing_polarity <- combined %>% mutate(missing_median_polarity = is.na(median_polarity))

combined_ah <- combined_missing_polarity %>% filter(grepl("^[A-H]", App)) %>% pull(missing_median_polarity)

combined_iz <- combined_missing_polarity %>% filter(grepl("^[I-Z]", App)) %>% pull(missing_median_polarity)

t.test(combined_ah,combined_iz)

## As seen from above t-test our hypothesis is correct


## Rating Imputations

### The thought here is apps that are quite recent [ within last 6 mos ] or more than 4 years old [app was never popular and is defunct now] don't have rating

combined_missing_rating <- combined %>% mutate(missing_rating = is.na(Rating))

combined_too_old_or_new <- combined_missing_rating %>% filter(Last.Updated > "2018-02-08" | Last.Updated < "2014-08-08") %>% pull(missing_rating)

combined_regular <- combined_missing_rating %>% filter(Last.Updated < "2018-02-08" & Last.Updated > "2014-08-07" ) %>% pull(missing_rating)

t.test(combined_too_old_or_new,combined_regular)


# definitely not mean or median. I don't think assuming 1474 apps without 
# ratings are 4+/5 is a good idea. Let's do KNN instead. 

summary(combined$Rating)

# determine xlim of margin plot
xlim_reviews = combined %>%
  select(Reviews, Rating) %>%
  filter(is.na(Rating))
max_xlim = max(xlim_reviews$Reviews)
# 
knn_imp_ratings_5 = kNN(combined, k =5, variable = c("Rating"))
knn_imp_ratings_5 %>%
  select(Reviews, Rating, Rating_imp) %>%
  marginplot(delimiter = "imp", main = "k = 5", xlim = c(0,max_xlim))


```

### Step 5 Exploratory Data Analysis

```{r}
## Attempting to distribution of Number of Installs against Category 

installsPerCategory <- combined %>% group_by(Category) %>% summarize(Installs=sum(`Install Floor`))
rownames(installsPerCategory) <- installsPerCategory$Category

print(installsPerCategory[order(-installsPerCategory$Installs),])

barplot(as.matrix(installsPerCategory$Installs),main = "Installs By Category",xlab ="Category",ylab="Installs",col="blue",beside=TRUE)



## Scatter Plot Rating against Installs 
installsPerCategory <- combined %>% group_by(Category) %>% summarize(Installs=sum(`Install Floor`))
rownames(installsPerCategory) <- installsPerCategory$Category

print(installsPerCategory[order(-installsPerCategory$Installs),])

barplot(as.matrix(installsPerCategory$Installs),main = "Installs By Category",xlab ="Category",ylab="Installs",col="blue",beside=TRUE)



combined_ah <- combined %>% filter(grepl("^[A-H]", App)) %>% group_by(Category) %>% summarize( median_polarity = median(median_polarity, na.rm = TRUE), median_subjectivity = median(median_subjectivity, na.rm = TRUE))

str(combined_ah)

```

### Step 6 Inferences

```{r}
# Our  hypothesis here is that number of installs should be higher for apps with higher rating

#Standardize installs across categories before doing correlation test
standardizeInstall <- combined %>% group_by(Category) %>% mutate(PercentOfTotalInstallsUnderCat = `Install Floor`/sum(`Install Floor`)) %>%  ungroup()  %>% select(PercentOfTotalInstallsUnderCat, Rating)

corr.test(standardizeInstall)


corr.test(combined %>% select(Reviews, Rating))


# Here the co-relation co-efficient between Reviews and Ratings is -0.01 and implies no correlation exists between the two

#Overall the attempt was to see if we can validate the assumptions that apps with higher ratings have more installs and hence also more reviews
```


### Step 7 Predictive Analytics and Modeling

```{r}
library(randomForest)
## Predicting reviews based on rating ?
regressionOnReviews <- lm(log(Reviews) ~ Rating,data = combined ,na.action = `na.exclude` )

summary(regressionOnReviews)


regressionOnInstalls <- lm(log(1+`Install Floor`) ~ Category,Rating,data = combined ,na.action = `na.exclude` )

summary(regressionOnInstalls)


## Sentiment Data
## Since we only have sentiment data for a:H we only consider APPS from A -> H )

combined_ah <- combined %>% filter(grepl("^[A-H]", App))

regressionOnRatingAgainstSentiment <- lm(Rating ~ median_polarity + median_subjectivity ,data = combined_ah ,na.action = `na.exclude` )

summary(regressionOnRatingAgainstSentiment)


regressionOnInstallsAgainstSentiment <- lm(log(1+`Install Floor`) ~ median_polarity + median_subjectivity ,data = combined_ah ,na.action = `na.exclude` )

summary(regressionOnInstallsAgainstSentiment)

combined$Last.Updated <- as.numeric(as.POSIXct(combined$Last.Updated, format="%Y-%m-%d"))
lMean <- mean(combined$Last.Updated)
stDev <- sd(combined$Last.Updated)

combined$Last.Updated <- (combined$Last.Updated - lMean)/stDev

regressionOnRatingAgainstLastUpdated <- lm(Rating ~ Last.Updated ,data = combined ,na.action = `na.exclude` )
summary(regressionOnRatingAgainstLastUpdated)

x = data.frame(log(as.numeric(as.POSIXct("2017-05-23", format="%Y-%m-%d") ) ) )
colnames(x) <- c("Last.Updated")
x$Last.Updated <- (x$Last.Updated - lMean)/stDev

std_r <- predict.lm(regressionOnRatingAgainstLastUpdated,x)
```


#### Random Forest
```{r}

cm <- combined %>% select(Rating,Reviews,`Install Floor`,Size,`Is Free`)
names(cm) <- make.names(names(cm))

trainIndex <- sample(nrow(cm), nrow(cm)*.7)
trainSet <- cm[trainIndex,]
validationSet <- cm[-trainIndex,]


str(trainSet)

regressor <- randomForest(formula=Rating ~ .,data=trainSet,na.action = `na.exclude`)
str(regressor)

print("Observed Error mse is quite high")
regressor.rsq

predicted_values <- as.vector(predict(regressor,newdata=validationSet %>% select(-Rating)))


plot(validationSet$Reviews,predicted_values,xlab="",ylab="",col="blue")
par(new=TRUE)
plot(validationSet$Reviews,validationSet$Rating,xlab="Reviews",ylab="Predicted_Rating(blue) and Rating(blue)",col="green")

## For lower value of Reviews vs Rating the model performs badly due to missing data 
```
